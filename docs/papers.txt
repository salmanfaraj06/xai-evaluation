[1] S. Ali et al., “Explainable Artificial Intelligence (XAI): What we know and what is left to attain Trustworthy Artificial Intelligence,” Inf. Fusion, vol. 99, p. 101805, Apr. 2023, doi: 10.1016/j.inffus.2023.101805.
[2] P. Angelov, E. Soares, R. Jiang, N. Arnold, and P. Atkinson, “Explainable artificial intelligence: an analytical review,” Wiley Interdisciplinary Reviews: Data Mining and Knowledge Discovery, vol. 11, Jul. 2021, doi: 10.1002/widm.1424.
[3] L. Arras, A. Osman, and W. Samek, “CLEVR-XAI: A benchmark dataset for the ground truth evaluation of neural network explanations,” Inf. Fusion, vol. 81, pp. 14–40, Mar. 2020, doi: 10.1016/j.inffus.2021.11.008.
[4] O. Arreche, T. Guntur, J. Roberts, and M. Abdallah, “E-XAI: Evaluating Black-Box Explainable AI Frameworks for Network Intrusion Detection,” IEEE Access, vol. 12, pp. 23954–23988, 2024, doi: 10.1109/access.2024.3365140.
[5] A. B. Arrieta et al., “Explainable Artificial Intelligence (XAI): Concepts, Taxonomies, Opportunities and Challenges toward Responsible AI,” Inf. Fusion, vol. 58, pp. 82–115, Oct. 2019, doi: 10.1016/j.inffus.2019.12.012.
[6] J. Černevičienė and A. Kabašinskas, “Explainable artificial intelligence (XAI) in finance: a systematic literature review,” Artif. Intell. Rev., vol. 57, p. 216, Jul. 2024, doi: 10.1007/s10462-024-10854-8.
[7] A. Chaddad, J. Peng, J. Xu, and A. Bouridane, “Survey of Explainable AI Techniques in Healthcare,” Sensors (Basel, Switzerland), vol. 23, Jan. 2023, doi: 10.3390/s23020634.
[8] R. Confalonieri, L. Çoba, B. Wagner, and T. Besold, “A historical perspective of explainable Artificial Intelligence,” Wiley Interdisciplinary Reviews: Data Mining and Knowledge Discovery, vol. 11, Oct. 2020, doi: 10.1002/widm.1391.
[9] D. Dembinsky, A. Lucieri, S. Frolov, H. Najjar, K. Watanabe, and A. Dengel, “Unifying VXAI: A Systematic Review and Framework for the Evaluation of Explainable AI,” Jun. 18, 2025, arXiv: arXiv:2506.15408. doi: 10.48550/arXiv.2506.15408.
[10] F. Di Martino and F. Delmastro, “Explainable AI for clinical and remote health applications: a survey on tabular and time series data,” Artificial Intelligence Review, vol. 56, pp. 5261–5315, Sep. 2022, doi: 10.1007/s10462-022-10304-3.
[11] W. Ding, M. Abdel-Basset, H. Hawash, and A. Ali, “Explainability of artificial intelligence methods, applications and challenges: A comprehensive survey,” Inf. Sci., vol. 615, pp. 238–292, Oct. 2022, doi: 10.1016/j.ins.2022.10.013.
[12] R. Dwivedi et al., “Explainable AI (XAI): Core Ideas, Techniques, and Solutions,” ACM Computing Surveys, vol. 55, pp. 1–33, Sep. 2022, doi: 10.1145/3561048.
[13] A. Fabregat-Hernández, J. Palanca, and V. Botti, “Exploring explainable AI: category theory insights into machine learning algorithms,” Machine Learning: Science and Technology, vol. 4, Dec. 2023, doi: 10.1088/2632-2153/ad1534.
[14] P. Hamm, M. Klesel, P. Coberger, and H. Wittmann, “Explanation matters: An experimental study on explainable AI,” Electronic Markets, vol. 33, pp. 1–21, May 2023, doi: 10.1007/s12525-023-00640-9.
[15] V. Hassija et al., “Interpreting Black-Box Models: A Review on Explainable Artificial Intelligence,” Cognitive Computation, vol. 16, pp. 45–74, Aug. 2023, doi: 10.1007/s12559-023-10179-8.
[16] A. Holzinger, “From Machine Learning to Explainable AI,” 2018 World Symposium on Digital Intelligence for Systems and Machines (DISA), pp. 55–66, Aug. 2018, doi: 10.1109/disa.2018.8490530.
[17] A. Holzinger, A. Saranti, C. Molnar, P. Biecek, and W. Samek, “Explainable AI Methods - A Brief Overview,” pp. 13–38, Jan. 2022, doi: 10.1007/978-3-031-04083-2_2.
[18] Md. T. Hosain, J. R. Jim, M. Mridha, and M. Kabir, “Explainable AI approaches in deep learning: Advancements, applications and challenges,” Comput. Electr. Eng., vol. 117, p. 109246, Jul. 2024, doi: 10.1016/j.compeleceng.2024.109246.
[19] R. Ibrahim and M. Shafiq, “Explainable Convolutional Neural Networks: A Taxonomy, Review, and Future Directions,” ACM Computing Surveys, vol. 55, pp. 1–37, Sep. 2022, doi: 10.1145/3563691.
[20] Md. A. Islam, M. Mridha, M. A. Jahin, and N. Dey, “A Unified Framework for Evaluating the Effectiveness and Enhancing the Transparency of Explainable AI Methods in Real-World Applications,” ArXiv, vol. abs/2412.03884, Dec. 2024, doi: 10.48550/arxiv.2412.03884.
[21] M. R. Islam, M. U. Ahmed, S. Barua, and S. Begum, “A Systematic Review of Explainable Artificial Intelligence in Terms of Different Application Domains and Tasks,” Applied Sciences, Jan. 2022, doi: 10.3390/app12031353.
[22] W. Jin, X. Li, M. Fatehi, and G. Hamarneh, “Guidelines and evaluation of clinical explainable AI in medical image analysis,” Medical image analysis, vol. 84, p. 102684, Feb. 2022, doi: 10.1016/j.media.2022.102684.
[23] D. Joyce, A. Kormilitzin, K. Smith, and A. Cipriani, “Explainable artificial intelligence for mental health through transparency and interpretability for understandability,” NPJ Digital Medicine, vol. 6, Jan. 2023, doi: 10.1038/s41746-023-00751-9.
[24] J. Kim, H. Maathuis, and D. Sent, “Human-centered evaluation of explainable AI applications: a systematic review,” Frontiers in Artificial Intelligence, vol. 7, Oct. 2024, doi: 10.3389/frai.2024.1456486.
[25] İ. Kök, F. Y. Okay, Ö. Muyanlı, and S. Özdemir, “Explainable Artificial Intelligence (XAI) for Internet of Things: A Survey,” IEEE Internet of Things Journal, vol. 10, pp. 14764–14779, Jun. 2022, doi: 10.1109/jiot.2023.3287678.
[26] A. Kuznietsov, B. Gyevnar, C. Wang, S. Peters, and S. Albrecht, “Explainable AI for Safe and Trustworthy Autonomous Driving: A Systematic Review,” IEEE Transactions on Intelligent Transportation Systems, vol. 25, pp. 19342–19364, Feb. 2024, doi: 10.1109/TITS.2024.3474469.
[27] V. Lai, Y. Zhang, C. Chen, Q. Liao, and C. Tan, “Selective Explanations: Leveraging Human Input to Align Explainable AI,” Proceedings of the ACM on Human-Computer Interaction, vol. 7, pp. 1–35, Jan. 2023, doi: 10.1145/3610206.
[28] M. Langer et al., “What Do We Want From Explainable Artificial Intelligence (XAI)? - A Stakeholder Perspective on XAI and a Conceptual Model Guiding Interdisciplinary XAI Research,” Artif. Intell., vol. 296, p. 103473, Feb. 2021, doi: 10.1016/j.artint.2021.103473.
[29] X.-H. Li et al., “A Survey of Data-Driven and Knowledge-Aware eXplainable AI,” IEEE Transactions on Knowledge and Data Engineering, vol. 34, pp. 29–49, Mar. 2020, doi: 10.1109/tkde.2020.2983930.
[30] M. Mersha, K. Lam, J. Wood, A. K. AlShami, and J. Kalita, “Explainable artificial intelligence: A survey of needs, techniques, applications, and future direction,” Neurocomputing, vol. 599, p. 128111, Sep. 2024, doi: 10.1016/j.neucom.2024.128111.
[31] B. Mittelstadt, C. Russell, and S. Wachter, “Explaining Explanations in AI,” Proceedings of the Conference on Fairness, Accountability, and Transparency, Nov. 2018, doi: 10.1145/3287560.3287574.
[32] E. Mohamed, K. Sirlantzis, and G. Howells, “A review of visualisation-as-explanation techniques for convolutional neural networks and their evaluation,” Displays, vol. 73, p. 102239, May 2022, doi: 10.1016/j.displa.2022.102239.
[33] S. Mohseni, N. Zarei, and E. Ragan, “A Multidisciplinary Survey and Framework for Design and Evaluation of Explainable AI Systems,” ACM Trans. Interact. Intell. Syst., vol. 11, pp. 24–24, Nov. 2018, doi: 10.1145/3387166.
[34] M. Nauta et al., “From Anecdotal Evidence to Quantitative Evaluation Methods: A Systematic Review on Evaluating Explainable AI,” ACM Computing Surveys, vol. 55, pp. 1–42, Jan. 2022, doi: 10.1145/3583558.
[35] S. Naveed, G. Stevens, and D. Robin-Kern, “An Overview of the Empirical Evaluation of Explainable AI (XAI): A Comprehensive Guideline for User-Centered Evaluation in XAI,” Applied Sciences, Dec. 2024, doi: 10.3390/app142311288.
[36] M. Pawlicki et al., “Evaluating the necessity of the multiple metrics for assessing explainable AI: A critical examination,” Neurocomputing, vol. 602, p. 128282, Jul. 2024, doi: 10.1016/j.neucom.2024.128282.
[37] N. Rodis, C. Sardianos, P. Radoglou-Grammatikis, P. Sarigiannidis, I. Varlamis, and G. Papadopoulos, “Multimodal Explainable Artificial Intelligence: A Comprehensive Review of Methodological Advances and Future Research Directions,” IEEE Access, vol. 12, pp. 159794–159820, Jun. 2023, doi: 10.1109/access.2024.3467062.
[38] Y. Rong et al., “Towards Human-Centered Explainable AI: A Survey of User Studies for Model Explanations,” IEEE Transactions on Pattern Analysis and Machine Intelligence, vol. 46, pp. 2104–2122, Oct. 2022, doi: 10.1109/TPAMI.2023.3331846.
[39] F. Russo, E. Schliesser, and J. Wagemans, “Connecting ethics and epistemology of AI,” AI & SOCIETY, pp. 1–19, Jan. 2023, doi: 10.1007/s00146-022-01617-6.
[40] M. Saarela and V. Podgorelec, “Recent Applications of Explainable AI (XAI): A Systematic Literature Review,” Applied Sciences, Oct. 2024, doi: 10.3390/app14198884.
[41] Z. Sadeghi et al., “A review of Explainable Artificial Intelligence in healthcare,” Comput. Electr. Eng., vol. 118, p. 109370, Aug. 2024, doi: 10.1016/j.compeleceng.2024.109370.
[42] W. Saeed and C. Omlin, “Explainable AI (XAI): A Systematic Meta-Survey of Current Challenges and Future Opportunities,” ArXiv, vol. abs/2111.06420, Nov. 2021, doi: 10.1016/j.knosys.2023.110273.
[43] A. Salih et al., “A review of evaluation approaches for explainable AI with applications in cardiology,” Artificial Intelligence Review, vol. 57, Aug. 2024, doi: 10.1007/s10462-024-10852-w.
[44] P. Schmidt, F. Biessmann, and T. Teubner, “Transparency and trust in artificial intelligence systems,” Journal of Decision Systems, vol. 29, pp. 260–278, Sep. 2020, doi: 10.1080/12460125.2020.1819094.
[45] G. Schwalbe and B. Finzel, “A comprehensive taxonomy for explainable artificial intelligence: a systematic survey of surveys on methods and concepts,” Data Mining and Knowledge Discovery, pp. 1–59, May 2021, doi: 10.1007/s10618-022-00867-8.
[46] T. Spinner, U. Schlegel, H. Schäfer, and M. El-Assady, “explAIner: A Visual Analytics Framework for Interactive and Explainable Machine Learning,” IEEE Transactions on Visualization and Computer Graphics, vol. 26, pp. 1064–1074, Jul. 2019, doi: 10.1109/tvcg.2019.2934629.
[47] N. Ullah, J. A. Khan, I. De Falco, and G. Sannino, “Explainable Artificial Intelligence: Importance, Use Domains, Stages, Output Shapes, and Challenges,” ACM Computing Surveys, vol. 57, pp. 1–36, Nov. 2024, doi: 10.1145/3705724.
[48] G. Vilone and L. Longo, “Notions of explainability and evaluation approaches for explainable artificial intelligence,” Inf. Fusion, vol. 76, pp. 89–106, Dec. 2021, doi: 10.1016/J.INFFUS.2021.05.009.
[49] J. Waa, E. Nieuwburg, A. Cremers, and M. A. Neerincx, “Evaluating XAI: A comparison of rule-based and example-based explanations,” Artif. Intell., vol. 291, p. 103404, Feb. 2021, doi: 10.1016/j.artint.2020.103404.
[50] D. Wang, Q. Yang, A. Abdul, and B. Lim, “Designing Theory-Driven User-Centric Explainable AI,” Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems, May 2019, doi: 10.1145/3290605.3300831.
[51] G. Yang, Q. Ye, and J. Xia, “Unbox the black-box for the medical explainable AI via multi-modal and multi-centre data fusion: A mini-review, two showcases and beyond,” An International Journal on Information Fusion, vol. 77, pp. 29–52, Feb. 2021, doi: 10.1016/j.inffus.2021.07.016.
[52] Y. Yang, L. Wen, and L. Li, “Explainable AI for time series prediction in economic mental health analysis,” Frontiers in Medicine, vol. 12, Jun. 2025, doi: 10.3389/fmed.2025.1591793.
[53] J. Zacharias, M. Von Zahn, J. Chen, and O. Hinz, “Designing a feature selection method based on explainable artificial intelligence,” Electronic Markets, vol. 32, pp. 2159–2184, Dec. 2022, doi: 10.1007/s12525-022-00608-1.
[54] X. Zheng et al., “F-Fidelity: A Robust Framework for Faithfulness Evaluation of Explainable AI,” ArXiv, vol. abs/2410.02970, Oct. 2024, doi: 10.48550/arxiv.2410.02970.
[55] N.-R. Zhou et al., “Explainable AI Frameworks: Navigating the Present Challenges and Unveiling Innovative Applications,” Algorithms, vol. 17, p. 227, May 2024, doi: 10.3390/a17060227.
[56] J. E. Zini and M. Awad, “On the Explainability of Natural Language Processing Deep Models,” ACM Computing Surveys, vol. 55, pp. 1–31, Jul. 2022, doi: 10.1145/3529755.
