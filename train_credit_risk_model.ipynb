{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Credit Risk Model Training - XGBoost 3.1.0\\n",
                "\\n",
                "**Objective**: Train an optimized XGBoost model for credit risk prediction with high precision and recall.\\n",
                "\\n",
                "**Dataset**: Credit risk dataset with 32,583 samples\\n",
                "**Target**: `loan_status` (1 = default, 0 = no default)\\n",
                "**XGBoost Version**: 3.1.0"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Install required packages (if needed)\\n",
                "# !pip install xgboost==3.1.0 scikit-learn pandas numpy matplotlib seaborn"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import pandas as pd\\n",
                "import numpy as np\\n",
                "import xgboost as xgb\\n",
                "from sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold\\n",
                "from sklearn.preprocessing import LabelEncoder\\n",
                "from sklearn.metrics import (\\n",
                "    classification_report, confusion_matrix, \\n",
                "    precision_score, recall_score, f1_score, roc_auc_score\\n",
                ")\\n",
                "import matplotlib.pyplot as plt\\n",
                "import seaborn as sns\\n",
                "import joblib\\n",
                "import warnings\\n",
                "warnings.filterwarnings('ignore')\\n",
                "\\n",
                "print(f'XGBoost version: {xgb.__version__}')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. Load and Explore Data"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Load dataset\\n",
                "df = pd.read_csv('usecases/credit_risk_dataset.csv')\\n",
                "\\n",
                "print(f'Dataset shape: {df.shape}')\\n",
                "print(f'\\\\nTarget distribution:\\\\n{df[\"loan_status\"].value_counts()}')\\n",
                "print(f'\\\\nDefault rate: {df[\"loan_status\"].mean():.2%}')\\n",
                "\\n",
                "df.head()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Check for missing values\\n",
                "print('Missing values per column:')\\n",
                "print(df.isnull().sum())\\n",
                "\\n",
                "# Data types\\n",
                "print('\\\\nData types:')\\n",
                "print(df.dtypes)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. Data Preprocessing"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Handle missing values\\n",
                "# Fill missing loan_int_rate with median\\n",
                "df['loan_int_rate'].fillna(df['loan_int_rate'].median(), inplace=True)\\n",
                "\\n",
                "# Fill missing person_emp_length with median\\n",
                "df['person_emp_length'].fillna(df['person_emp_length'].median(), inplace=True)\\n",
                "\\n",
                "print('Missing values after imputation:')\\n",
                "print(df.isnull().sum().sum())"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Encode categorical variables\\n",
                "categorical_cols = ['person_home_ownership', 'loan_intent', 'loan_grade', 'cb_person_default_on_file']\\n",
                "\\n",
                "label_encoders = {}\\n",
                "for col in categorical_cols:\\n",
                "    le = LabelEncoder()\\n",
                "    df[col] = le.fit_transform(df[col])\\n",
                "    label_encoders[col] = le\\n",
                "\\n",
                "print('Encoded categorical variables')\\n",
                "df.head()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Separate features and target\\n",
                "X = df.drop('loan_status', axis=1)\\n",
                "y = df['loan_status']\\n",
                "\\n",
                "print(f'Features shape: {X.shape}')\\n",
                "print(f'Target shape: {y.shape}')\\n",
                "print(f'\\\\nFeature names: {list(X.columns)}')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Train-test split (80-20)\\n",
                "X_train, X_test, y_train, y_test = train_test_split(\\n",
                "    X, y, test_size=0.2, random_state=42, stratify=y\\n",
                ")\\n",
                "\\n",
                "print(f'Training set: {X_train.shape[0]} samples')\\n",
                "print(f'Test set: {X_test.shape[0]} samples')\\n",
                "print(f'\\\\nTraining set default rate: {y_train.mean():.2%}')\\n",
                "print(f'Test set default rate: {y_test.mean():.2%}')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. Train XGBoost Model (Optimized for Precision & Recall)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Calculate scale_pos_weight for imbalanced data\\n",
                "scale_pos_weight = (y_train == 0).sum() / (y_train == 1).sum()\\n",
                "print(f'Scale pos weight: {scale_pos_weight:.2f}')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# XGBoost parameters optimized for precision and recall\\n",
                "params = {\\n",
                "    'objective': 'binary:logistic',\\n",
                "    'eval_metric': ['logloss', 'auc'],\\n",
                "    'max_depth': 6,\\n",
                "    'learning_rate': 0.05,\\n",
                "    'n_estimators': 300,\\n",
                "    'min_child_weight': 3,\\n",
                "    'subsample': 0.8,\\n",
                "    'colsample_bytree': 0.8,\\n",
                "    'gamma': 0.1,\\n",
                "    'reg_alpha': 0.1,\\n",
                "    'reg_lambda': 1.0,\\n",
                "    'scale_pos_weight': scale_pos_weight,\\n",
                "    'random_state': 42,\\n",
                "    'n_jobs': -1,\\n",
                "    'tree_method': 'hist',  # Fast histogram-based algorithm\\n",
                "    'device': 'cpu'  # Use 'cuda' if GPU available\\n",
                "}\\n",
                "\\n",
                "print('Model parameters:')\\n",
                "for key, value in params.items():\\n",
                "    print(f'  {key}: {value}')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Train model with early stopping\\n",
                "model = xgb.XGBClassifier(**params)\\n",
                "\\n",
                "model.fit(\\n",
                "    X_train, y_train,\\n",
                "    eval_set=[(X_train, y_train), (X_test, y_test)],\\n",
                "    verbose=50\\n",
                ")\\n",
                "\\n",
                "print('\\\\nModel training complete!')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4. Model Evaluation"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Predictions\\n",
                "y_pred = model.predict(X_test)\\n",
                "y_pred_proba = model.predict_proba(X_test)[:, 1]\\n",
                "\\n",
                "# Metrics\\n",
                "precision = precision_score(y_test, y_pred)\\n",
                "recall = recall_score(y_test, y_pred)\\n",
                "f1 = f1_score(y_test, y_pred)\\n",
                "auc = roc_auc_score(y_test, y_pred_proba)\\n",
                "\\n",
                "print('='*60)\\n",
                "print('MODEL PERFORMANCE')\\n",
                "print('='*60)\\n",
                "print(f'Precision: {precision:.4f}')\\n",
                "print(f'Recall: {recall:.4f}')\\n",
                "print(f'F1-Score: {f1:.4f}')\\n",
                "print(f'ROC-AUC: {auc:.4f}')\\n",
                "print('='*60)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Classification report\\n",
                "print('\\\\nClassification Report:')\\n",
                "print(classification_report(y_test, y_pred, target_names=['No Default', 'Default']))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Confusion matrix\\n",
                "cm = confusion_matrix(y_test, y_pred)\\n",
                "\\n",
                "plt.figure(figsize=(8, 6))\\n",
                "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \\n",
                "            xticklabels=['No Default', 'Default'],\\n",
                "            yticklabels=['No Default', 'Default'])\\n",
                "plt.title('Confusion Matrix')\\n",
                "plt.ylabel('True Label')\\n",
                "plt.xlabel('Predicted Label')\\n",
                "plt.tight_layout()\\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Feature importance\\n",
                "feature_importance = pd.DataFrame({\\n",
                "    'feature': X.columns,\\n",
                "    'importance': model.feature_importances_\\n",
                "}).sort_values('importance', ascending=False)\\n",
                "\\n",
                "plt.figure(figsize=(10, 6))\\n",
                "sns.barplot(data=feature_importance, x='importance', y='feature')\\n",
                "plt.title('Feature Importance')\\n",
                "plt.xlabel('Importance Score')\\n",
                "plt.tight_layout()\\n",
                "plt.show()\\n",
                "\\n",
                "print('\\\\nTop 5 Most Important Features:')\\n",
                "print(feature_importance.head())"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 5. Cross-Validation"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 5-fold cross-validation\\n",
                "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\\n",
                "cv_scores = cross_val_score(model, X_train, y_train, cv=cv, scoring='roc_auc', n_jobs=-1)\\n",
                "\\n",
                "print('Cross-Validation ROC-AUC Scores:')\\n",
                "print(f'  Fold scores: {cv_scores}')\\n",
                "print(f'  Mean: {cv_scores.mean():.4f}')\\n",
                "print(f'  Std: {cv_scores.std():.4f}')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 6. Save Model"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Save model\\n",
                "model_path = 'usecases/xgboost_credit_risk_new.pkl'\\n",
                "joblib.dump(model, model_path)\\n",
                "\\n",
                "print(f'✅ Model saved to: {model_path}')\\n",
                "print(f'\\\\nModel info:')\\n",
                "print(f'  XGBoost version: {xgb.__version__}')\\n",
                "print(f'  Features: {len(X.columns)}')\\n",
                "print(f'  Classes: {model.classes_}')\\n",
                "print(f'  Precision: {precision:.4f}')\\n",
                "print(f'  Recall: {recall:.4f}')\\n",
                "print(f'  F1-Score: {f1:.4f}')\\n",
                "print(f'  ROC-AUC: {auc:.4f}')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 7. Test Model Loading"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Load and test the saved model\\n",
                "loaded_model = joblib.load(model_path)\\n",
                "\\n",
                "# Verify it works\\n",
                "test_pred = loaded_model.predict(X_test[:5])\\n",
                "print('Test predictions from loaded model:')\\n",
                "print(test_pred)\\n",
                "\\n",
                "print('\\\\n✅ Model successfully saved and loaded!')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Summary\\n",
                "\\n",
                "**Model Performance:**\\n",
                "- Precision: Measures how many predicted defaults are actual defaults\\n",
                "- Recall: Measures how many actual defaults are correctly identified\\n",
                "- F1-Score: Harmonic mean of precision and recall\\n",
                "- ROC-AUC: Overall model discrimination ability\\n",
                "\\n",
                "**Next Steps:**\\n",
                "1. Use the saved model (`xgboost_credit_risk_new.pkl`) in the HEXEval framework\\n",
                "2. Run XAI evaluation (SHAP, LIME, Anchor, DiCE)\\n",
                "3. Get persona-based recommendations\\n",
                "\\n",
                "**Model is compatible with:**\\n",
                "- XGBoost 3.1.0\\n",
                "- Python 3.8+\\n",
                "- HEXEval framework"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.10.0"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}