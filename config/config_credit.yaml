data:
  path: loan_default.csv
  target: Default
  drop_cols:
    - LoanID
  categorical:
    - Education
    - EmploymentType
    - MaritalStatus
    - LoanPurpose
  binary:
    - HasMortgage
    - HasDependents
    - HasCoSigner
  numeric:
    - Age
    - Income
    - LoanAmount
    - CreditScore
    - MonthsEmployed
    - NumCreditLines
    - InterestRate
    - LoanTerm
    - DTIRatio
  test_size: 0.2
  random_state: 42

preprocessing:
  scale_numeric: true   # standardize numeric features
  impute_strategy: median  # fill missing numeric values with median

model:
  type: xgboost
  params:
    n_estimators: 200       # number of trees
    max_depth: 5            # tree depth
    learning_rate: 0.1      # shrinkage
    subsample: 0.8          # row subsampling
    colsample_bytree: 0.8   # feature subsampling
    min_child_weight: 1     # min leaf weight
    reg_lambda: 1.0         # L2 regularization
    objective: binary:logistic
    eval_metric: logloss

evaluation:
  fidelity:
    subset_size: 150   # number of test instances for insertion/deletion
    steps: 50          # curve resolution
  anchor:
    threshold: 0.9      # desired precision threshold
    subset_size: 60     # number of instances for anchors
  dice:
    total_cfs: 3        # counterfactuals per instance
    subset_size: 10     # instances for counterfactuals
  shap:
    background_size: 1200  # background rows for SHAP explainer
  lime:
    num_samples: 5000      # LIME perturbation samples
    num_features: 10       # LIME top features
    stability_subset_size: 30 # instances for stability check
  human_llm:
    runs_per_method: 2      # LLM ratings per persona-method
    n_instances: 5         # test instances sampled per persona-method
    top_k_explanation: 5    # top-k features shown in explanation text

paths:
  model_dir: outputs/models
  metrics_dir: outputs/vxai_metrics
  human_eval_dir: outputs/human_eval_templates
  pretrained_model: xgboost_loan_default_research_v2.pkl
